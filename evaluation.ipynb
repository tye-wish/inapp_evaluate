{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tye/anaconda3/envs/tahoe/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.16) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tahoe_api.api import TahoeQuery, import_data_td, get_latest_table_generic, table_create, table_delete, check_table_exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "since_dt = '2023-01-01'\n",
    "end_dt = '2023-09-01'\n",
    "\n",
    "# V2 model has user_id=61b2599df8ce712b2305d746 which means records with this user_id indicates the auto-approve from the model.\n",
    "# As a comparison, the prediction of `uncertain` will always reviewed by other user_id.\n",
    "# Therefore, filtering the user_id can give us the positive or negative predictions.\n",
    "\n",
    "appropriate_statement = '='\n",
    "inappropriate_statement = '!='\n",
    "\n",
    "basic_sql = \"\"\"\n",
    "    WITH tagging AS (\n",
    "    SELECT job_id,\n",
    "    product_id,\n",
    "    is_adult,\n",
    "    inappropriate_reason,\n",
    "    subcategory,\n",
    "    dt,\n",
    "    hr\n",
    "    FROM sweeper.true_tags\n",
    "    WHERE dt >= '{since_dt}' and dt <= '{end_dt}'\n",
    "    and user_id{condition}'61b2599df8ce712b2305d746'\n",
    "    and action = 120 -- V2_INAPPROPRIATE_TAG_COMPLETED\n",
    "    ),\n",
    "    audit AS (\n",
    "    SELECT tagging_job_id,\n",
    "    product_id,\n",
    "    is_adult,\n",
    "    inappropriate_reason,\n",
    "    subcategory,\n",
    "    dt,\n",
    "    hr\n",
    "    FROM sweeper.inappropriate_audit_events\n",
    "    WHERE dt >= '{since_dt}' and dt <= '{end_dt}'\n",
    "    AND action = 4 -- audit job completed\n",
    "    )\n",
    "\n",
    "    SELECT tagging.job_id, tagging.inappropriate_reason as tagging_inappropriate_reason, audit.inappropriate_reason as audit_inappropriate_reason, tagging.dt\n",
    "\n",
    "    FROM tagging\n",
    "    LEFT JOIN audit ON tagging.job_id = audit.tagging_job_id\n",
    "\"\"\"\n",
    "\n",
    "appropriate_sql = basic_sql.format(since_dt=since_dt, end_dt=end_dt, condition=appropriate_statement)\n",
    "inappropriate_sql = basic_sql.format(since_dt=since_dt, end_dt=end_dt, condition=inappropriate_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to push metrics to gateway: local variable 'GATEWAY_URL' referenced before assignment\n",
      "WARNING:root:Failed to push metrics to gateway: local variable 'GATEWAY_URL' referenced before assignment\n",
      "WARNING:root:Failed to push metrics to gateway: local variable 'GATEWAY_URL' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "rows = TahoeQuery(appropriate_sql, db_type='presto').run_query()\n",
    "# df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34266791, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rows)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('inappropriate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>tagging_inappropriate_reason</th>\n",
       "      <th>audit_inappropriate_reason</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64d46767a4f16e7efec76ad4</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64d468812cbb48e64f28a6be</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64d468e288ae1e62b9e9bd7f</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64d466a04252ba792acdb26d</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64d4692ff72de532f530a8f8</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34266786</th>\n",
       "      <td>64416174a38ede187f5833d4</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34266787</th>\n",
       "      <td>6441616978d4827b63215c2a</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34266788</th>\n",
       "      <td>644168d4bccd95942ddcc10d</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34266789</th>\n",
       "      <td>64416f1d711203914a5e4c21</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34266790</th>\n",
       "      <td>64416f65af86221801401730</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34266791 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            job_id tagging_inappropriate_reason  \\\n",
       "0         64d46767a4f16e7efec76ad4                         None   \n",
       "1         64d468812cbb48e64f28a6be                         None   \n",
       "2         64d468e288ae1e62b9e9bd7f                         None   \n",
       "3         64d466a04252ba792acdb26d                         None   \n",
       "4         64d4692ff72de532f530a8f8                         None   \n",
       "...                            ...                          ...   \n",
       "34266786  64416174a38ede187f5833d4                         None   \n",
       "34266787  6441616978d4827b63215c2a                         None   \n",
       "34266788  644168d4bccd95942ddcc10d                         None   \n",
       "34266789  64416f1d711203914a5e4c21                         None   \n",
       "34266790  64416f65af86221801401730                         None   \n",
       "\n",
       "          audit_inappropriate_reason          dt  \n",
       "0                                NaN  2023-08-10  \n",
       "1                                NaN  2023-08-10  \n",
       "2                                NaN  2023-08-10  \n",
       "3                                NaN  2023-08-10  \n",
       "4                                NaN  2023-08-10  \n",
       "...                              ...         ...  \n",
       "34266786                         NaN  2023-04-20  \n",
       "34266787                         NaN  2023-04-20  \n",
       "34266788                         NaN  2023-04-20  \n",
       "34266789                         NaN  2023-04-20  \n",
       "34266790                         NaN  2023-04-20  \n",
       "\n",
       "[34266791 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pd.isna(df['audit_inappropriate_reason'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict = ['nan' for v in df['tagging_inappropriate_reason'] if v is None]\n",
    "# gt = ['nan' for v in df['audit_inappropriate_reason'] if pd.isna(v)]\n",
    "\n",
    "# predict.extend(df['tagging_inappropriate_reason'].tolist())\n",
    "predict.extend(['inappropriate' if val != 'nan' else val for val in df['tagging_inappropriate_reason'].tolist()])\n",
    "gt.extend(['inappropriate' if val != 'nan' else val for val in df['audit_inappropriate_reason'].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_file(csv_file: str):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df.fillna('nan')\n",
    "\n",
    "    predict_array = ['inappropriate' if val != 'nan' else val for val in df['tagging_inappropriate_reason'].tolist()]\n",
    "    gt_array = ['inappropriate' if val != 'nan' else val for val in df['audit_inappropriate_reason'].tolist()]\n",
    "\n",
    "    return predict_array, gt_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_array = []\n",
    "gt_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in ['appropriate.csv', 'inappropriate.csv']:\n",
    "    pred, gt = load_data_from_file(file_name)\n",
    "    predict_array.extend(pred)\n",
    "    gt_array.extend(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [73033121, 107299912]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b219f0e20e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inappropriate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inappropriate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/tye/anaconda3/envs/tahoe/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tye/anaconda3/envs/tahoe/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1660\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1663\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tye/anaconda3/envs/tahoe/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tye/anaconda3/envs/tahoe/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1465\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tye/anaconda3/envs/tahoe/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1275\u001b[0m                          str(average_options))\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tye/anaconda3/envs/tahoe/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tye/anaconda3/envs/tahoe/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 320\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [73033121, 107299912]"
     ]
    }
   ],
   "source": [
    "precision_score(gt_array, predict_array, pos_label='inappropriate'), recall_score(gt_array, predict_array, pos_label='inappropriate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inappropriate', 'nan'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tahoe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
